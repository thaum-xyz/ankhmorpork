apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    prometheus: k8s
    role: alert-rules
  name: thaum-rules
  namespace: monitoring
spec:
  groups:
  - name: testing.rules
    rules:
    - alert: CPUStealTimeHigh
      annotations:
        description: CPU Steal Time is very high on {{ $labels.instance }} hypervisor.
          This can lead to VM being stalled.
        runbook_url: https://runbooks.thaum.xyz/runbooks/thaum-xyz/CPUStealTimeHigh
        summary: High CPU Steal Time
      expr: |
        sum by (instance) (rate(node_cpu_seconds_total{mode="steal"}[3m])) / count by (instance) (node_cpu_seconds_total{mode="steal"}) > 0.1
      for: 20m
      labels:
        severity: warning
    - expr: time() - kube_namespace_created
      record: :kube_namespace_created
    - alert: SiteNotUP
      annotations:
        description: UptimeRobot reports site {{ $labels.url }} not to be up for 15m.
          Site is either paused or down.
        runbook_url: https://runbooks.thaum.xyz/runbooks/thaum-xyz/SiteNotUP
        summary: UptimeRobot reports site to be up.
      expr: uptimerobot_monitor_status != 2
      for: 15m
      labels:
        severity: critical
    - alert: KubePodOOMKilled
      annotations:
        description: Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container
          }}) was OOMKilled.
        summary: Pod was OOMKilled.
      expr: (kube_pod_container_status_last_terminated_reason{reason="OOMKilled"}
        == 1) and on(container, namespace, pod) (increase(kube_pod_container_status_restarts_total[5m])
        > 0)
      labels:
        severity: warning
  - name: custom node alert rules
    rules:
    - alert: PackagesAvailable
      annotations:
        description: '{{ $value }} packages are available for upgrade. Maybe it is
          time to upgrade?'
        runbook_url: https://runbooks.thaum.xyz/runbooks/thaum-xyz/PackagesAvailable
        summary: Packages are available for upgrade
      expr: |
        sum by (node,instance) (yum_upgrades_pending) > 200
        or
        sum by (node,instance) (apt_upgrades_pending) > 200
      for: 48h
      labels:
        severity: info
    - alert: RebootRequired
      annotations:
        description: Instance '{{ $labels.instance }}' was upgraded and now requires
          a reboot.
        runbook_url: https://runbooks.thaum.xyz/runbooks/thaum-xyz/RebootRequired
        summary: Reboot is required to finish package upgrade
      expr: node_reboot_required > 0
      for: 4h
      labels:
        severity: info
  - name: alert rules specific to thaum.xyz
    rules:
    - alert: FilesystemReadOnly
      annotations:
        description: Filesystem went read-only on {{ $labels.instance }}. Check FS
          for possible corruption.
        runbook_url: https://runbooks.thaum.xyz/runbooks/thaum-xyz/FilesystemReadOnly
        summary: Filesystem went read-only possibly due to device error.
      expr: |
        node_filesystem_readonly{fstype=~"(vfat|ext4|xfs)"} != 0
      labels:
        severity: critical
    - alert: TouchscreenNotAvailable
      annotations:
        description: Powercycle device {{ $labels.instance }}
        runbook_url: https://runbooks.thaum.xyz/runbooks/thaum-xyz/TouchscreenNotAvailable
        summary: Touchscreen not available and automatic remediation failed to restore
          it
      expr: |
        devices_input_touchscreen_up{environment="lancre.thaum.xyz"} == 0 or absent(devices_input_touchscreen_up{environment="lancre.thaum.xyz"})
      for: 30m
      labels:
        severity: critical
    - alert: TemperaturesNotAvailable
      annotations:
        description: Temperature data is gone. Immediatelly switch off all relays
          and check OW bus.
        runbook_url: https://runbooks.thaum.xyz/runbooks/thaum-xyz/TemperaturesNotAvailable
        summary: Cannot obtain temperature data
      expr: |
        absent(evok_temperature_celsius{environment="lancre.thaum.xyz"})
      for: 15m
      labels:
        env: lancre
        severity: critical
  - name: openshift.rules
    rules:
    - alert: HighlyAvailableWorkloadIncorrectlySpread
      annotations:
        description: Workload {{ $labels.namespace }}/{{ $labels.workload }} is incorrectly
          spread across multiple nodes which breaks high-availability requirements.
          Since the workload is using persistent volumes, manual intervention is needed.
          Please follow the guidelines provided in the runbook of this alert to fix
          this issue.
        runbook_url: https://github.com/openshift/runbooks/blob/master/alerts/HighlyAvailableWorkloadIncorrectlySpread.md
        summary: Highly-available workload is incorrectly spread across multiple nodes
          and manual intervention is needed.
      expr: |
        count by (workload, namespace) (
          kube_pod_info{node!=""}
          * on(namespace,pod) group_left(workload)
          (
            kube_pod_spec_volumes_persistentvolumeclaims_info
            * on(namespace,pod) group_left(workload)
            (
              namespace_workload_pod:kube_pod_owner:relabel
              * on(namespace,workload,workload_type) group_left()
              (
                count without(pod) (namespace_workload_pod:kube_pod_owner:relabel) > 1
              )
            )
          ) == 1
      for: 1h
      labels:
        severity: warning
